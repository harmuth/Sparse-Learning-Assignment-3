---
title: "Assignment 3"
author: "Philip Harmuth"
date: "2018-01-26"
output: pdf_document
---

# Exploratory questions
First we load the data and packages.

```{r, warning=FALSE, include=TRUE}
library(msgl)
library(ggplot2)
library(dplyr)
library(tidyr)

data(PrimaryCancers)
ord_class <- order(classes)
ord_mir <- order(colMeans(x), decreasing = TRUE)
x <- x[ord_class, ord_mir]
classes <- classes[ord_class]
image(Matrix(x))
```

And plot the matrix.

## Class means
First we calculate the class means for each column
```{r}
class.col.means <- data.frame(class = classes) %>% 
  bind_cols(as.data.frame(x)) %>%
  group_by(class) %>%
  summarise_all(mean)
```

and plots the column means for each class
```{r, fig.cap=  "Columns means by class and column"}
plot.cols <- class.col.means %>%
  gather(col,means,-class) %>%
  group_by(class) %>%
  mutate(col.num = row_number()) %>%
  arrange(class,col.num)

ggplot(plot.cols,aes(x=col.num,y=means)) +
  geom_line() + facet_wrap(~class)
```

We see generally declining means over the columns for each class with some noise, which is expected since column of $X$ are ordered by declining means.

## PCA on the residual matrix
We now do PCA on the residual matrix by first subtracting the class means per columns from $X$ and then using the singular value decomposition of the residual matrix so calculate the principal components.
```{r, fig.cap = "Image of residual matrix", cache = TRUE}
X.mean.matrix <- data.frame(class = classes) %>% 
  left_join(class.col.means) %>% 
  select(-class)
X.residuals <- x-X.mean.matrix
X.residuals.svd <- svd(X.residuals)
pc <- t(X.residuals.svd$d * t(X.residuals.svd$u)) %>%
  as.data.frame() %>% 
  bind_cols(data.frame(class = classes))
image(Matrix(as.matrix(X.residuals)))
```


We now plot the first and second principal component against eachother with each observation colored according to class.


```{r, fig.cap = "First and second PC"}
ggplot(pc, aes(V1,V2,col=class)) +
  geom_point() +
  ylab("2nd PC") + 
  xlab("1st PC")

```


```{r, fig.cap = "First and second PC. Classes as one vs all"}
class.pc <- data.frame(oneclass = classes) %>% 
  left_join(pc)
ggplot(pc, aes(V1,V2,col=class)) +
  geom_point() +
  ylab("2nd PC") + 
  xlab("1st PC")

```

From this plot we see that the first two principal captures variance of the residual matrix in more or less perpendicular directions making nice round'ish cloud. From this cluster we can't quite see if some classes cluster together. To more clearly see if this is the case we make same plot for each class where we distinguish between points belonging to the class or not.

```{r, fig.cap = "One vs rest plots for 1st and 2nd PC."}
class.pc <- data.frame(class = rep(unique(classes),each=length(pc$class)),
           target =  rep(pc$class,length(unique(classes))),
           pc1 = rep(pc$V1,length(unique(classes))),
           pc2 = rep(pc$V2,length(unique(classes)))) %>%
  mutate(same = class == target)

ggplot(class.pc, aes(pc1,pc2,col=same)) +
  geom_point() +
  facet_wrap(~class)+
  ylab("2nd PC") + 
  xlab("1st PC")

```


Here we don't see any significant clustering of certain classes and we can't use the 1st and 2nd PC to seperate points belonging to different classes.

## Sparse prinicipal components

First we implement the algorithm for one rank sparse PCA

```{r}
ORS.PCA <- function(X, t, max.iter, convergence.threshold, verbose = 0) {
  over.threshold <- TRUE
  v <- matrix(1/dim(X)[2], ncol = 1, nrow = dim(X)[2])
  m <- 1
  u <- X %*% v / sqrt(sum((X %*% v)^2))
  v.f <- function (lambda, y) {
    sign(t(X) %*% y) * pmax(t(X) %*% y - lambda, 0)
  }
  while(over.threshold | m > max.iter) {
    new.u <- X %*% v / sqrt(sum((X %*% v) ^ 2))
    if(max(v.f(0, new.u)) < t){
      lambda <- 0
    } else {
      opt.func <- function(lambda){ abs(max(v.f(lambda, new.u)) - t)}
      lambda <- optimise(opt.func, c(0, max(v.f(0, new.u))))$minimum
    }
    
    new.v <- v.f(lambda, new.u)
    
    if((max(abs(new.v-v))<convergence.threshold) & (max(abs(new.u-u)) < convergence.threshold)){
      over.threshold = FALSE
    }
    if(verbose > 0){
      cat("iter =",m,"\n","v convergence:",max(abs(new.v-v)),"\n","u convergence:",max(abs(new.u-u)),"\n", "lambda:", lambda,"\n")
    }
    
    v <- new.v
    u <- new.u
    m <- m + 1
  }
  return(list(v = v, u = u, convergence = !over.threshold, n_iter = m - 1))
}
```


Here we don't see any significant clustering of certain classes and we can't use the 1st and 2nd PC to seperate points belonging to different classes.
